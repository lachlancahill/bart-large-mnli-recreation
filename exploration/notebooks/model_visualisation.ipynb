{
 "cells": [
  {
   "cell_type": "code",
   "id": "db2ca8b85222b233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import hiddenlayer as hl\n",
    "import torch\n",
    "from transformers import MistralForSequenceClassification, LlamaTokenizerFast"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:15:11.521482Z",
     "start_time": "2024-06-14T06:15:11.505965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_repo = 'h2oai/h2o-danube2-1.8b-base'\n",
    "device = 'cpu'"
   ],
   "id": "6ab470847cd7d27a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:15:13.469580Z",
     "start_time": "2024-06-14T06:15:12.326038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MistralForSequenceClassification.from_pretrained(hf_repo, num_labels=3, device_map=device,\n",
    "                                                         torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(hf_repo)"
   ],
   "id": "dfe736ee1b6546c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at h2oai/h2o-danube2-1.8b-base and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:18:31.473785Z",
     "start_time": "2024-06-14T06:18:31.461437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    num_added_toks = tokenizer.add_special_tokens({'pad_token': '<|pad_token|>'})\n",
    "    assert num_added_toks == 1\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n"
   ],
   "id": "e461ac3b762c0677",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:18:31.680235Z",
     "start_time": "2024-06-14T06:18:31.648860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "premises = [\n",
    "    \"and\",\n",
    "]\n",
    "\n",
    "hypotheses = [\n",
    "    'my'\n",
    "]\n",
    "\n",
    "inputs = tokenizer(premises, hypotheses, truncation='only_first', padding=\"max_length\",\n",
    "                    max_length=25, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "inputs"
   ],
   "id": "4fd834bbd4fac4ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000,   304,   586]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:02:14.121189Z",
     "start_time": "2024-06-14T06:01:41.751794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "model = MLP()\n",
    "batch_size = 2\n",
    "# device='meta' -> no memory is consumed for visualization\n",
    "model_graph = draw_graph(model, input_size=(batch_size, 128), device='meta')\n",
    "model_graph.visual_graph"
   ],
   "id": "d011096c19d677bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lachl\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:86: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1 or self.sliding_window is not None:\n",
      "C:\\Users\\lachl\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "C:\\Users\\lachl\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:119: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len > self.max_seq_len_cached:\n",
      "C:\\Users\\lachl\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:662: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
      "C:\\Users\\lachl\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1320: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.config.pad_token_id is None and batch_size != 1:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.onnx' has no attribute '_optimize_trace'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mhl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint64\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\hiddenlayer\\graph.py:143\u001B[0m, in \u001B[0;36mbuild_graph\u001B[1;34m(model, args, input_names, transforms, framework_transforms)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument args must be provided for Pytorch models.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 143\u001B[0m     \u001B[43mimport_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m framework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001B[1;32m~\\PycharmProjects\\bart-large-mnli-recreation\\.venv\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001B[0m, in \u001B[0;36mimport_graph\u001B[1;34m(hl_graph, model, args, input_names, verbose)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimport_graph\u001B[39m(hl_graph, model, args, input_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;66;03m# TODO: add input names to graph\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001B[39;00m\n\u001B[0;32m     70\u001B[0m     trace, out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_get_trace_graph(model, args)\n\u001B[1;32m---> 71\u001B[0m     torch_graph \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimize_trace\u001B[49m(trace, torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mOperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX)\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;66;03m# Dump list of nodes (DEBUG only)\u001B[39;00m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch.onnx' has no attribute '_optimize_trace'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# make_dot(model_outputs[0].mean(), params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c7eef785fb42330d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
